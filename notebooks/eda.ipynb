{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe412587-dc1f-47e3-8249-4ec3ed779553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ../data/processed/structured/games_2016.parquet -> games_2016 (alias games_16), shape=(832, 196)\n",
      "Loaded ../data/processed/structured/games_2017.parquet -> games_2017 (alias games_17), shape=(834, 196)\n",
      "Loaded ../data/processed/structured/games_2018.parquet -> games_2018 (alias games_18), shape=(845, 196)\n",
      "Loaded ../data/processed/structured/games_2019.parquet -> games_2019 (alias games_19), shape=(848, 196)\n",
      "Loaded ../data/processed/structured/games_2020.parquet -> games_2020 (alias games_20), shape=(542, 196)\n",
      "Loaded ../data/processed/structured/games_2021.parquet -> games_2021 (alias games_21), shape=(849, 196)\n",
      "Loaded ../data/processed/structured/games_2022.parquet -> games_2022 (alias games_22), shape=(854, 196)\n",
      "Loaded ../data/processed/structured/games_2023.parquet -> games_2023 (alias games_23), shape=(868, 196)\n",
      "Loaded ../data/processed/structured/games_2024.parquet -> games_2024 (alias games_24), shape=(874, 196)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\n",
    "# directory containing game parquet files (relative to this notebook)\n",
    "path = Path('..') / 'data' / 'processed' / 'structured'\n",
    "files = sorted(path.glob('*.parquet'))\n",
    "# load exactly one DataFrame per season (keep the first file encountered for each year)\n",
    "games = {}  # maps YYYY -> DataFrame\n",
    "for f in files:\n",
    "    # read parquet first so any I/O/parquet-engine errors surface immediately\n",
    "    df = pd.read_parquet(f)\n",
    "    fname = f.name\n",
    "    m = re.search(r'(19|20)\\d{2}', fname)\n",
    "    if m:\n",
    "        year = m.group(0)\n",
    "    else:\n",
    "        # fallback: use filename without suffix\n",
    "        year = fname.rsplit('.parquet', 1)[0]\n",
    "    # normalize to a 4-digit year string when possible\n",
    "    year_str = year if (isinstance(year, str) and len(str(year)) == 4 and str(year).isdigit()) else str(year)\n",
    "    # if we've already loaded a DataFrame for this season, skip further files\n",
    "    if year_str in games:\n",
    "        # skip duplicates for the same season\n",
    "        continue\n",
    "    # register the DataFrame for this season\n",
    "    games[year_str] = df\n",
    "    # expose short-name globals: games_YY (e.g. games_16) and games_YYYY\n",
    "    short = year_str[-2:] if year_str.isdigit() and len(year_str) == 4 else year_str\n",
    "    globals()[f'games_{year_str}'] = df\n",
    "    globals()[f'games_{short}'] = df\n",
    "    print(f'Loaded {f} -> games_{year_str} (alias games_{short}), shape={df.shape}')\n",
    "# convenience alias: dfs points to the per-season mapping we just built\n",
    "dfs = games\n",
    "# use dfs['2017'] or globals()['games_17'] as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8f7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: df, columns: 196, chunks: 20\n",
      "df_chunk_01 (874, 10) columns-> ['week', 'home_team', 'away_team', 'home_points', 'away_points', 'home_team_x', 'home_conference', 'home_team_y', 'home_defensiveTDs', 'home_firstDowns']\n",
      "df_chunk_02 (874, 10) columns-> ['home_fumblesLost', 'home_fumblesRecovered', 'home_interceptionTDs', 'home_interceptionYards', 'home_interceptions', 'home_kickReturnTDs', 'home_kickReturnYards', 'home_kickReturns', 'home_kickingPoints', 'home_netPassingYards']\n",
      "df_chunk_03 (874, 10) columns-> ['home_passesDeflected', 'home_passesIntercepted', 'home_passingTDs', 'home_puntReturnTDs', 'home_puntReturnYards', 'home_puntReturns', 'home_qbHurries', 'home_rushingAttempts', 'home_rushingTDs', 'home_rushingYards']\n",
      "df_chunk_04 (874, 10) columns-> ['home_sacks', 'home_tackles', 'home_tacklesForLoss', 'home_totalFumbles', 'home_totalYards', 'home_turnovers', 'home_yardsPerPass', 'home_yardsPerRushAttempt', 'home_team_conference', 'home_off_passingPlays_explosiveness']\n",
      "df_chunk_05 (874, 10) columns-> ['home_off_passingPlays_successRate', 'home_off_passingPlays_totalPPA', 'home_off_passingPlays_ppa', 'home_off_rushingPlays_explosiveness', 'home_off_rushingPlays_successRate', 'home_off_rushingPlays_totalPPA', 'home_off_rushingPlays_ppa', 'home_off_passingDowns_explosiveness', 'home_off_passingDowns_successRate', 'home_off_passingDowns_ppa']\n",
      "df_chunk_06 (874, 10) columns-> ['home_off_standardDowns_explosiveness', 'home_off_standardDowns_successRate', 'home_off_standardDowns_ppa', 'home_off_openFieldYardsTotal', 'home_off_openFieldYards', 'home_off_secondLevelYardsTotal', 'home_off_secondLevelYards', 'home_off_lineYardsTotal', 'home_off_lineYards', 'home_off_stuffRate']\n",
      "df_chunk_07 (874, 10) columns-> ['home_off_powerSuccess', 'home_off_explosiveness', 'home_off_successRate', 'home_off_totalPPA', 'home_off_ppa', 'home_off_drives', 'home_off_plays', 'home_def_passingPlays_explosiveness', 'home_def_passingPlays_successRate', 'home_def_passingPlays_totalPPA']\n",
      "df_chunk_08 (874, 10) columns-> ['home_def_passingPlays_ppa', 'home_def_rushingPlays_explosiveness', 'home_def_rushingPlays_successRate', 'home_def_rushingPlays_totalPPA', 'home_def_rushingPlays_ppa', 'home_def_passingDowns_explosiveness', 'home_def_passingDowns_successRate', 'home_def_passingDowns_ppa', 'home_def_standardDowns_explosiveness', 'home_def_standardDowns_successRate']\n",
      "df_chunk_09 (874, 10) columns-> ['home_def_standardDowns_ppa', 'home_def_openFieldYardsTotal', 'home_def_openFieldYards', 'home_def_secondLevelYardsTotal', 'home_def_secondLevelYards', 'home_def_lineYardsTotal', 'home_def_lineYards', 'home_def_stuffRate', 'home_def_powerSuccess', 'home_def_explosiveness']\n",
      "df_chunk_10 (874, 10) columns-> ['home_def_successRate', 'home_def_totalPPA', 'home_def_ppa', 'home_def_drives', 'home_def_plays', 'away_team_x', 'away_conference', 'away_team_y', 'away_defensiveTDs', 'away_firstDowns']\n",
      "df_chunk_11 (874, 10) columns-> ['away_fumblesLost', 'away_fumblesRecovered', 'away_interceptionTDs', 'away_interceptionYards', 'away_interceptions', 'away_kickReturnTDs', 'away_kickReturnYards', 'away_kickReturns', 'away_kickingPoints', 'away_netPassingYards']\n",
      "df_chunk_12 (874, 10) columns-> ['away_passesDeflected', 'away_passesIntercepted', 'away_passingTDs', 'away_puntReturnTDs', 'away_puntReturnYards', 'away_puntReturns', 'away_qbHurries', 'away_rushingAttempts', 'away_rushingTDs', 'away_rushingYards']\n",
      "df_chunk_13 (874, 10) columns-> ['away_sacks', 'away_tackles', 'away_tacklesForLoss', 'away_totalFumbles', 'away_totalYards', 'away_turnovers', 'away_yardsPerPass', 'away_yardsPerRushAttempt', 'away_team_conference', 'away_off_passingPlays_explosiveness']\n",
      "df_chunk_14 (874, 10) columns-> ['away_off_passingPlays_successRate', 'away_off_passingPlays_totalPPA', 'away_off_passingPlays_ppa', 'away_off_rushingPlays_explosiveness', 'away_off_rushingPlays_successRate', 'away_off_rushingPlays_totalPPA', 'away_off_rushingPlays_ppa', 'away_off_passingDowns_explosiveness', 'away_off_passingDowns_successRate', 'away_off_passingDowns_ppa']\n",
      "df_chunk_15 (874, 10) columns-> ['away_off_standardDowns_explosiveness', 'away_off_standardDowns_successRate', 'away_off_standardDowns_ppa', 'away_off_openFieldYardsTotal', 'away_off_openFieldYards', 'away_off_secondLevelYardsTotal', 'away_off_secondLevelYards', 'away_off_lineYardsTotal', 'away_off_lineYards', 'away_off_stuffRate']\n",
      "df_chunk_16 (874, 10) columns-> ['away_off_powerSuccess', 'away_off_explosiveness', 'away_off_successRate', 'away_off_totalPPA', 'away_off_ppa', 'away_off_drives', 'away_off_plays', 'away_def_passingPlays_explosiveness', 'away_def_passingPlays_successRate', 'away_def_passingPlays_totalPPA']\n",
      "df_chunk_17 (874, 10) columns-> ['away_def_passingPlays_ppa', 'away_def_rushingPlays_explosiveness', 'away_def_rushingPlays_successRate', 'away_def_rushingPlays_totalPPA', 'away_def_rushingPlays_ppa', 'away_def_passingDowns_explosiveness', 'away_def_passingDowns_successRate', 'away_def_passingDowns_ppa', 'away_def_standardDowns_explosiveness', 'away_def_standardDowns_successRate']\n",
      "df_chunk_18 (874, 10) columns-> ['away_def_standardDowns_ppa', 'away_def_openFieldYardsTotal', 'away_def_openFieldYards', 'away_def_secondLevelYardsTotal', 'away_def_secondLevelYards', 'away_def_lineYardsTotal', 'away_def_lineYards', 'away_def_stuffRate', 'away_def_powerSuccess', 'away_def_explosiveness']\n",
      "df_chunk_19 (874, 10) columns-> ['away_def_successRate', 'away_def_totalPPA', 'away_def_ppa', 'away_def_drives', 'away_def_plays', 'game_id', 'season', 'season_type', 'start_date', 'conference_game']\n",
      "df_chunk_20 (874, 6) columns-> ['neutral_site', 'venue', 'spread', 'total', 'point_diff', 'favorite']\n"
     ]
    }
   ],
   "source": [
    "# Split DataFrame columns into chunks of `chunk_size` columns each\n",
    "def chunk_df_columns(df, chunk_size=10, prefix='df_chunk'):\n",
    "    \"\"\"Return a dict of DataFrames, each containing up to chunk_size columns.\n",
    "    Keys are prefix_01, prefix_02, ...\n",
    "    \"\"\"\n",
    "    cols = list(df.columns)\n",
    "    chunks = {}\n",
    "    for i in range(0, len(cols), chunk_size):\n",
    "        chunk_cols = cols[i:i+chunk_size]\n",
    "        name = f\"{prefix}_{i//chunk_size+1:02d}\"\n",
    "        # use .loc to preserve column order and copy to avoid view warnings\n",
    "        chunks[name] = df.loc[:, chunk_cols].copy()\n",
    "    return chunks\n",
    "\n",
    "# Pick a sensible default dataframe variable if present (adjust names as needed)\n",
    "for candidate in ('df_a', 'df', 'df_16', 'df_2016'):\n",
    "    if candidate in globals():\n",
    "        target_name = candidate\n",
    "        break\n",
    "else:\n",
    "    raise NameError('No target dataframe found. Define `df` or `df_a` or df_YYYY beforehand.')\n",
    "\n",
    "target_df = globals()[target_name]\n",
    "chunks = chunk_df_columns(target_df, chunk_size=10, prefix=f'{target_name}_chunk')\n",
    "print(f\"Target: {target_name}, columns: {len(target_df.columns)}, chunks: {len(chunks)}\")\n",
    "for name, cdf in chunks.items():\n",
    "    print(name, cdf.shape, 'columns->', list(cdf.columns))\n",
    "\n",
    "# Optionally expose chunked dataframes as globals (uncomment to enable)\n",
    "# for name, cdf in chunks.items():\n",
    "#     globals()[name] = cdf\n",
    "#     print('Created global', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd015ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "who_covers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
